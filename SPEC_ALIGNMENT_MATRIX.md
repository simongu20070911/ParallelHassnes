# Spec Alignment Matrix (FUNCTIONALITY_SPEC.md → Implementation)

This file is generated/maintained by `tools/spec_alignment_audit.py`.

Legend: PASS = implemented and testable; N/A = not a runtime requirement; PARTIAL/GAP = misalignment.

| Spec line | Kind | Requirement | Status | Evidence | Verification | Notes |
|---:|---|---|---|---|---|---|
| 28 | REQUIRED | **Runner (worker code)**: a software process/service (written by us) that executes jobs on a host that has Codex CLI and required tools; creates attempt directories, sets `CODEX_HOME`, spawns `codex exec`, and writes logs/artifacts to disk in real time. | PASS | parallelhassnes/runner/runner.py:31<br>parallelhassnes/runner/runner.py:650<br>parallelhassnes/runner/runner.py:660 | tests/test_scenarios.py<br>tests/test_file_order_and_immutability.py |  |
| 93 | REQUIRED | `batch_goal_summary` (required; more than 150 words; human-readable statement of what this batch is trying to achieve) | PASS | parallelhassnes/validation/launch_table.py:62 | tests/test_scenarios.py |  |
| 120 | MUST | must identify a source step (at minimum): `resume_from.step_id` | PASS | parallelhassnes/validation/launch_table.py:36<br>parallelhassnes/scheduler/scheduler.py:310 | tests/test_resume_selector_determinism.py<br>tests/test_scenarios.py |  |
| 121 | MUST | must define a source attempt selector (default: `latest_successful`): | PASS | parallelhassnes/validation/launch_table.py:36<br>parallelhassnes/scheduler/scheduler.py:310 | tests/test_resume_selector_determinism.py<br>tests/test_scenarios.py |  |
| 126 | MUST | must have a stable resume base for the selected source attempt (a session snapshot) so later steps can resume from any earlier step without mutating the source | PASS | parallelhassnes/validation/launch_table.py:36<br>parallelhassnes/scheduler/scheduler.py:310 | tests/test_resume_selector_determinism.py<br>tests/test_scenarios.py |  |
| 127 | MUST | `resume_from` implies a dependency: the harness must treat it as if the step also `depends_on` the source step | PASS | parallelhassnes/validation/launch_table.py:36<br>parallelhassnes/scheduler/scheduler.py:310 | tests/test_resume_selector_determinism.py<br>tests/test_scenarios.py |  |
| 141 | MUST | Harness must materialize its centralized configuration as a well-known on-disk file that the orchestrator can read: `runs/_system/harness_config.json`. | PASS | parallelhassnes/config/harness_config.py:109<br>parallelhassnes/harness/harness.py:9 | tests/test_scenarios.py |  |
| 142 | MUST | `runs/_system/harness_config.json` is an atomic snapshot (readable without contacting the harness) and must include a stable `harness_config_version`. | PASS | parallelhassnes/config/harness_config.py:109<br>parallelhassnes/harness/harness.py:9 | tests/test_scenarios.py |  |
| 143 | MUST | The harness must preserve each `harness_config_version` as a write-once snapshot at `runs/_system/harness_config_versions/<harness_config_version>.json` for as long as any batch artifacts reference it. | PASS | parallelhassnes/config/harness_config.py:109<br>parallelhassnes/harness/harness.py:9 | tests/test_scenarios.py |  |
| 152 | MUST | scoreboard defaults such as `heartbeat_stale_after_seconds` (default 2700; must be >= 1800) and any stuck auto-remediation enablement | PASS | parallelhassnes/config/harness_config.py:85<br>parallelhassnes/validation/contracts.py:42 | tests/test_scoreboard_derivation_statuses.py |  |
| 153 | MUST | Launch Tables may override only the subset explicitly allowed by harness policy; the harness must compute and record “effective defaults” for each batch in `batch_meta.json`. | PASS | parallelhassnes/interfaces/fs_queue.py:72 | tests/test_effective_defaults_merge.py |  |
| 154 | MUST | For reproducibility, `batch_meta.json` must include a `harness_config_version` identifier and the “effective defaults” sufficient to interpret the batch behavior later (conceptual; see 7.1.1). | PASS | parallelhassnes/interfaces/fs_queue.py:72 | tests/test_effective_defaults_merge.py |  |
| 160 | MUST | `harness_config_version` | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 161 | MUST | `written_at` | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 162 | MUST | `interfaces`: | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 163 | MUST | `api_mode`: | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 164 | MUST | `enabled` (boolean) | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 165 | MUST | `auth_mode` (conceptual; e.g., `none \| local_trust \| token`) | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 166 | MUST | `filesystem_queue_mode`: | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 167 | MUST | `enabled` (boolean) | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 168 | MUST | queue roots/paths may be included as opaque strings (optional; conceptual) | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 169 | MUST | default policies (conceptual): `execution_policy`, `timeouts`, `retries`, `retention_policy` | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 170 | MUST | scoreboard defaults: `heartbeat_stale_after_seconds` (default 2700; must be >= 1800) and stuck auto-remediation enablement | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 171 | MUST | runner pool / capabilities (conceptual): enough to explain scheduling decisions (e.g., which runners exist and whether they are accepting work) | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 172 | MUST | limits (conceptual): maximum batch/job/step sizes and any other safety caps | PASS | parallelhassnes/config/harness_config.py:99<br>parallelhassnes/validation/contracts.py:11 | tests/test_scenarios.py |  |
| 175 | MUST_NOT | secrets (API tokens, private keys). The orchestrator and runners must obtain secrets from their own credential stores. | PASS | parallelhassnes/config/harness_config.py:15 | tests/test_harness_config_secret_denylist.py |  |
| 181 | REQUIRED | required fields present | PASS | parallelhassnes/validation/launch_table.py:46<br>parallelhassnes/interfaces/fs_queue.py:12 | tests/test_scenarios.py |  |
| 193 | MUST | `batch_id` | PASS | parallelhassnes/validation/launch_table.py:21<br>schemas/launch_table.normalized.schema.json:6 | tests/test_scenarios.py<br>tests/test_effective_defaults_merge.py |  |
| 194 | MUST | `spec_version` (if used) | PASS | parallelhassnes/validation/launch_table.py:21<br>schemas/launch_table.normalized.schema.json:6 | tests/test_scenarios.py<br>tests/test_effective_defaults_merge.py |  |
| 195 | MUST | submission timestamp (`submitted_at`) | PASS | parallelhassnes/validation/launch_table.py:21<br>schemas/launch_table.normalized.schema.json:6 | tests/test_scenarios.py<br>tests/test_effective_defaults_merge.py |  |
| 196 | MUST | `harness_config_version` (the config version effective at submit time; referencable via `runs/_system/harness_config_versions/<harness_config_version>.json`) | PASS | parallelhassnes/validation/launch_table.py:21<br>schemas/launch_table.normalized.schema.json:6 | tests/test_scenarios.py<br>tests/test_effective_defaults_merge.py |  |
| 197 | MUST | `batch_goal_summary` (required; more than 150 words) | PASS | parallelhassnes/validation/launch_table.py:21<br>schemas/launch_table.normalized.schema.json:6 | tests/test_scenarios.py<br>tests/test_effective_defaults_merge.py |  |
| 198 | MUST | Launch Table snapshot or reference: | PASS | parallelhassnes/validation/launch_table.py:21<br>schemas/launch_table.normalized.schema.json:6 | tests/test_scenarios.py<br>tests/test_effective_defaults_merge.py |  |
| 199 | MUST | either inline normalized Launch Table, or | PASS | parallelhassnes/validation/launch_table.py:21<br>schemas/launch_table.normalized.schema.json:6 | tests/test_scenarios.py<br>tests/test_effective_defaults_merge.py |  |
| 200 | MUST | `launch_table_ref` + `launch_table_sha256` | PASS | parallelhassnes/validation/launch_table.py:21<br>schemas/launch_table.normalized.schema.json:6 | tests/test_scenarios.py<br>tests/test_effective_defaults_merge.py |  |
| 201 | MUST | normalized `jobs[]` including each job’s `job_id`, `working_directory`, and `steps[]` with each step’s `step_id` and dependency wiring (`depends_on[]`, `resume_from` if present). | PASS | parallelhassnes/validation/launch_table.py:21<br>schemas/launch_table.normalized.schema.json:6 | tests/test_scenarios.py<br>tests/test_effective_defaults_merge.py |  |
| 202 | MUST | resolved defaults/policies that materially affect execution (e.g., sandbox/approvals/search flags, timeouts, retry policy) as selected by the harness for this batch. | PASS | parallelhassnes/validation/launch_table.py:21<br>schemas/launch_table.normalized.schema.json:6 | tests/test_scenarios.py<br>tests/test_effective_defaults_merge.py |  |
| 205 | MUST_NOT | runtime attempt results, `run_id` lists, or per-attempt status (those live in attempt `meta.json` / `state.json` and job pointers like `current.json`) | PASS | parallelhassnes/interfaces/fs_queue.py:61 | tests/test_effective_defaults_merge.py | batch_meta is write-once; runtime attempt results live under attempt dirs + current.json. |
| 206 | MUST_NOT | the step1-produced `codex_thread_id` for future resumes (unknown at submission time; may be recorded later if captured, e.g. via raw events, via attempt `meta.json` and propagated via `current.json`) | PASS | parallelhassnes/runner/runner.py:179 | tests/test_codex_thread_id_capture.py | Thread id is not in batch_meta at submit time; captured later into current.json when enabled. |
| 230 | MUST_NOT | (Optional) If deep auditing is enabled, the runner may also persist raw event streams, but orchestration must not depend on them. | PASS | parallelhassnes/runner/runner.py:77 | tests/test_scenarios.py | Raw event streams are optional and never used for orchestration decisions. |
| 241 | REQUIRED | an explicit `codex_thread_id` when required (advanced / non-isolated stores). | PASS | parallelhassnes/runner/runner.py:188<br>parallelhassnes/runner/runner.py:679 | tests/test_resume_explicit_thread_id_preference.py |  |
| 255 | SHOULD | Cancel requests should: | PASS | parallelhassnes/ops/cancel.py:16 | tests/test_cancel_semantics.py | Spec uses SHOULD; implementation supports cancel-before-start and cancel-while-running with terminalization. |
| 280 | MUST | The system must validate `final.json` against the expected schema. | PASS | parallelhassnes/runner/runner.py:230 | tests/test_schema_files.py<br>tests/test_file_order_and_immutability.py |  |
| 322 | MUST | Run attempt directories must be uniquely named per run attempt to avoid collisions under parallelism. | PASS | parallelhassnes/core/paths.py:44<br>parallelhassnes/runner/runner.py:71 | tests/test_concurrency_safety.py |  |
| 323 | MUST | Run attempt directory locations must be discoverable from IDs without reading run-file contents (at minimum: `batch_id`, `job_id`, `step_id`, `run_id`). | PASS | parallelhassnes/storage/runs_store.py:68 | tests/test_attempt_dir_resolution.py | Resolves via `current.json` (index) when available; otherwise resolves by direct `<run_id>/` or by suffix scan of attempt dir names (no JSON reads). |
| 324 | MUST | `<run_dir_name>` must include `run_id` (e.g., as a suffix like `..._<run_id>` or as the full directory name). | PASS | parallelhassnes/storage/runs_store.py:97 | tests/test_attempt_dir_resolution.py |  |
| 343 | MUST | write semantics: updates must be performed via “write temp + rename” so readers never see partial JSON. | PASS | parallelhassnes/core/atomic_io.py:10<br>parallelhassnes/core/state_update.py:7 | tests/test_state_transition_guard.py |  |
| 344 | MUST | reader semantics: readers must tolerate `state.json` being momentarily missing (e.g., right at attempt start) and treat it as `queued` / `initializing`. | PASS | parallelhassnes/runner/runner.py:146<br>parallelhassnes/runner/runner.py:888 | tests/test_scenarios.py | Runner writes an initial queued snapshot immediately; readers also tolerate missing state as best-effort. |
| 349 | MUST | terminality: once `status` is one of `{succeeded \| failed \| canceled \| needs_attention}`, the run attempt is ended and `status` must never change again for that run attempt. | PASS | parallelhassnes/core/state_update.py:11 | tests/test_state_transition_guard.py<br>tests/test_cancel_semantics.py |  |
| 351 | MUST | `started_at` must be present when `status` is `running` or terminal | PASS | parallelhassnes/validation/contracts.py:120 | tests/test_file_order_and_immutability.py |  |
| 352 | MUST | `ended_at` must be present when `status` is terminal | PASS | parallelhassnes/validation/contracts.py:120 | tests/test_file_order_and_immutability.py |  |
| 362 | MUST_NOT | unique per run attempt (`run_id`); must not be shared between concurrent attempts | PASS | parallelhassnes/runner/runner.py:650<br>parallelhassnes/runner/runner.py:52 | tests/test_concurrency_safety.py |  |
| 365 | MUST | If no API key is available, the runner must make the existing `auth.json` available to the attempt-local `CODEX_HOME` (recommended: symlink from a runner-local credential store). | PASS | parallelhassnes/runner/runner.py:577 | tests/test_scenarios.py | Best-effort: uses env-injected API key when present, else symlinks runner-local ~/.codex auth/config into attempt-local CODEX_HOME. |
| 417 | SHOULD | it should contain enough information to locate attempts and resume bases deterministically | PASS | parallelhassnes/storage/runs_store.py:97<br>parallelhassnes/runner/runner.py:440 | tests/test_attempt_dir_resolution.py | Spec uses SHOULD; attempt dirs are discoverable by IDs and current.json includes resume_base_dir pointers. |
| 418 | SHOULD | it should not be relied on to explain why something is blocked; blocked/ready reasons are derived in the scoreboard from `batch_meta.json` dependency wiring + attempt `state.json` / `current.json` pointers | PASS | parallelhassnes/scoreboard/scoreboards.py:251 | tests/test_scoreboard_derivation_statuses.py | Blocked reasons are derived in scoreboards; current.json remains a minimal mutable index. |
| 435 | MUST | `batch_id`, `job_id`, `updated_at` | PASS | parallelhassnes/core/current_update.py:1<br>parallelhassnes/runner/runner.py:422 | tests/test_scenarios.py<br>tests/test_codex_thread_id_capture.py |  |
| 436 | MUST | `steps` map keyed by `step_id`, where each value includes: | PASS | parallelhassnes/core/current_update.py:1<br>parallelhassnes/runner/runner.py:422 | tests/test_scenarios.py<br>tests/test_codex_thread_id_capture.py |  |
| 437 | MUST | `latest`: | PASS | parallelhassnes/core/current_update.py:1<br>parallelhassnes/runner/runner.py:422 | tests/test_scenarios.py<br>tests/test_codex_thread_id_capture.py |  |
| 438 | MUST | `run_id` | PASS | parallelhassnes/core/current_update.py:1<br>parallelhassnes/runner/runner.py:422 | tests/test_scenarios.py<br>tests/test_codex_thread_id_capture.py |  |
| 439 | MUST | `attempt_dir` (path to the run attempt directory) | PASS | parallelhassnes/core/current_update.py:1<br>parallelhassnes/runner/runner.py:422 | tests/test_scenarios.py<br>tests/test_codex_thread_id_capture.py |  |
| 440 | MUST | `resume_base_dir` (path to that attempt’s `codex_home/`) | PASS | parallelhassnes/core/current_update.py:1<br>parallelhassnes/runner/runner.py:422 | tests/test_scenarios.py<br>tests/test_codex_thread_id_capture.py |  |
| 441 | MUST | optional `codex_thread_id` | PASS | parallelhassnes/core/current_update.py:1<br>parallelhassnes/runner/runner.py:422 | tests/test_scenarios.py<br>tests/test_codex_thread_id_capture.py |  |
| 442 | MUST | `latest_successful` (same fields as `latest`) when different | PASS | parallelhassnes/core/current_update.py:1<br>parallelhassnes/runner/runner.py:422 | tests/test_scenarios.py<br>tests/test_codex_thread_id_capture.py |  |
| 462 | MUST | In practice: in an open batch, any `resume_base_dir` currently referenced by that batch’s `current.json` must be treated as protected from GC. | PASS | parallelhassnes/retention/gc.py:129 | tests/test_scenarios.py<br>tests/test_retention_policy.py |  |
| 472 | REQUIRED | Harness updates `current.json` to point at this attempt/run (optional at start, required by completion). | PASS | parallelhassnes/runner/runner.py:156 | tests/test_scenarios.py |  |
| 500 | MUST | “stuck” steps: `running` with no `state.json.last_heartbeat_at` heartbeat update for a threshold (default 45 minutes; must be >= 30 minutes) | PASS | parallelhassnes/scoreboard/scoreboards.py:103<br>parallelhassnes/validation/contracts.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 519 | MUST | **Batch header** | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 520 | MUST | `batch_id`, `submitted_at` (from `batch_meta.json`), `computed_at` (time this scoreboard view is computed) | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 521 | MUST | `batch_goal_summary` (from `batch_meta.json`) | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 522 | MUST | totals: `jobs_total`, `steps_total` | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 523 | MUST | `heartbeat_stale_after_seconds` (default: 2700 / 45 minutes; must be >= 1800 / 30 minutes) | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 524 | MUST | **Counts by step status** (step-level, derived; see below): `blocked`, `ready`, `running`, `succeeded`, `failed`, `needs_attention`, `canceled` | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 525 | MUST | **Attention list** (ordered by severity): stuck steps, then `needs_attention`, then failed steps | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 526 | MUST | **Running list**: each running step includes: | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 527 | MUST | identifiers: `job_id`, `step_id`, `run_id`, `runner_id` | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 528 | MUST | `attempt_dir` | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 529 | MUST | `current_item` (if present) | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 530 | MUST | `last_heartbeat_at` and derived `seconds_since_last_heartbeat` | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 531 | MUST | `started_at` and derived `run_duration_seconds` | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 532 | MUST | **Blocked list**: each blocked step includes: | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 533 | MUST | `job_id`, `step_id` | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 534 | MUST | blocking reasons: unsatisfied `depends_on[]` (and/or missing resume base for `resume_from`) | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 535 | MUST | **Failure list**: each failed/needs_attention step includes: | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 536 | MUST | `job_id`, `step_id`, `run_id`, `attempt_dir` | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 537 | MUST | host outcome: `state.json.status`, `exit_code` (if present) | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 538 | MUST | optional agent outcome: `final.json.status` + `final.json.summary` (display only) | PASS | parallelhassnes/scoreboard/scoreboards.py:46 | tests/test_scoreboard_derivation_statuses.py |  |
| 671 | MUST | Every run attempt that may be resumed from must produce a **resume base** (session snapshot), stored as an immutable directory snapshot (the completed attempt-local `codex_home/` once frozen at attempt end). | PASS | parallelhassnes/runner/runner.py:54<br>parallelhassnes/runner/runner.py:560 | tests/test_scenarios.py |  |
| 672 | MUST_NOT | A resume run must not mutate the source attempt’s resume base. Instead it must **copy** the source resume base into the new run attempt’s session store before invoking `codex exec resume`. | PASS | parallelhassnes/runner/runner.py:561 | tests/test_scenarios.py |  |
| 676 | MUST | A resume run must execute on a runner that can read the source attempt directory (and thus its `codex_home/`), or the system must first copy the resume base to the destination runner. | PASS | parallelhassnes/runner/runner.py:534 | tests/test_runner_locality.py |  |
| 677 | REQUIRED | In filesystem-only MVP mode, “same runner” is sufficient but not strictly required if the `runs/` store (or the resume base) is accessible from the destination runner. | PASS | parallelhassnes/runner/runner.py:533 | tests/test_runner_locality.py |  |
| 681 | MUST | If the session store may contain multiple threads, resuming must use an explicit `codex_thread_id`. | PASS | parallelhassnes/runner/runner.py:188 | tests/test_resume_explicit_thread_id_preference.py | If a thread id is known (captured or provided), resume uses it; otherwise it falls back to resume --last inside an isolated session store. |
| 702 | REQUIRED | The system must define one workspace policy per job (selectable): shared vs isolated. | PASS | parallelhassnes/workspace/policy.py:20<br>parallelhassnes/scheduler/scheduler.py:1 | tests/test_workspace_policy_isolated.py | Scheduler resolves a per-job workspace; isolated policy creates/reuses `runs/<batch_id>/<job_id>/_workspace`. |
| 706 | REQUIRED | Chosen workspace policy must be explicit and recorded in `meta.json`. | PASS | parallelhassnes/runner/runner.py:117 | tests/test_workspace_policy_isolated.py | `meta.json.environment_snapshot.workspace_policy` and `workspace_root` record the resolved policy + workspace. |
| 711 | REQUIRED | Resume changes conversation state, not filesystem rollback: resume steps run against the **latest job workspace** at execution time. | PASS | parallelhassnes/workspace/policy.py:24<br>parallelhassnes/scheduler/scheduler.py:1 | tests/test_workspace_policy_isolated.py | Steps share the same per-job workspace across the batch; resume seeding only copies `codex_home/`. |
| 720 | REQUIRED | Minimum ops: submit batch. | PASS | parallelhassnes/interfaces/fs_queue.py:1<br>parallelhassnes/api/app.py:74 | tests/test_scenarios.py | Filesystem queue mode ingests JSON launch tables; API mode provides `POST /v1/batches`. |
| 721 | REQUIRED | Minimum ops: list/query batch and job status. | PASS | parallelhassnes/scoreboard/scoreboards.py:1<br>parallelhassnes/api/app.py:114 | tests/test_scoreboard_derivation_statuses.py | Scoreboards are written to disk and available via API endpoints. |
| 722 | REQUIRED | Minimum ops: fetch per-run artifacts by name. | PASS | parallelhassnes/api/app.py:152 | tests/test_scenarios.py | API `GET /v1/attempts/artifact` fetches attempt artifacts by name (or by IDs). |
| 723 | REQUIRED | Minimum ops: stream or tail per-run events (when enabled). | PASS | parallelhassnes/api/app.py:176 | tests/test_scenarios.py | API `GET /v1/attempts/events` tails `codex.events.jsonl` (if captured). |
| 724 | REQUIRED | Minimum ops: cancel a run. | PASS | parallelhassnes/ops/cancel.py:1<br>parallelhassnes/api/app.py:224 | tests/test_cancel_semantics.py | Best-effort cancel updates `state.json.status=canceled` and kills the process group when applicable. |
| 725 | REQUIRED | Minimum ops: trigger resume/retry steps. | PASS | parallelhassnes/ops/overrides.py:1<br>parallelhassnes/api/app.py:234 | tests/test_retry_backoff_and_mode.py | Overrides provide force-retry/requeue control; scheduler consumes overrides on tick. |
| 757 | MUST | Misread: you can “resume from any earlier step” just by recording a `codex_thread_id`. Clarification: resuming mutates the conversation state; to support jumping back/branching, you must preserve a per-attempt resume base (session snapshot) and copy it into a new attempt’s session store before resuming. | N/A |  |  | Spec misread clarification; not a code requirement. |
| 763 | MUST | Reference completeness check: any referenced field/path must be defined once (where it lives, who writes it, and when it changes). | N/A |  |  | Spec editing checklist item; not a runtime requirement. |
| 766 | MUST | Contradiction scan: search for “immutable”, “append-only”, “must”, and cross-check against any “updated” language nearby. | N/A |  |  | Spec editing checklist item; not a runtime requirement. |
